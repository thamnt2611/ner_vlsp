{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"we_for_ner.ipynb","provenance":[],"authorship_tag":"ABX9TyMlcU+idbZGaBW5sNN8INeZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcmGTndFwhhE","executionInfo":{"elapsed":26495,"status":"ok","timestamp":1623467514889,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"06a09d1d-ee19-4c2a-caee-8c125c28ef5e"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"34T1LIT2ivIQ"},"source":["import re\n","import gensim\n","from gensim.models import Word2Vec, KeyedVectors\n","import torch\n","import torch.nn as nn\n","torch.manual_seed(1)\n","import numpy as np\n","import torch.optim as optim\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gV5xf2C8J2av","executionInfo":{"elapsed":21,"status":"ok","timestamp":1623460134448,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"58a6af3f-b892-4aba-9564-8b1372ce5ec3"},"source":["print(torch.cuda.get_device_name(0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4KOVkM7ugxzg"},"source":["###**Prepare data for training word2vec from scratch**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ia6lAMI6kvQ4","executionInfo":{"elapsed":11,"status":"ok","timestamp":1623467520736,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"78eeb7c1-3db9-4d17-e120-ddd02dc7aa20"},"source":["reg = re.compile(r\"[A-Za-z_]+\")\n","re.match(reg, \"7\") ==  None"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"XXcf0DhQjseN"},"source":["datapath = '/content/drive/My Drive/nlp/vlsp 2018/data/train2.txt'\n","outfile = open('/content/drive/My Drive/nlp/vlsp 2018/data/brown_input_rmv.txt', 'w+')\n","reg = re.compile(r\"[A-Za-z_]+\")\n","reg_num = re.compile(r\"[0-9_/]+\")\n","with open(datapath, 'rb') as f:\n","  text = f.read().decode(\"utf-8\")\n","  br_input = []\n","  for sent in text.split(\"\\n\\n\"):\n","    w_sent = []\n","    for line in sent.split('\\n'):\n","      for i in line.split('\\t'):\n","        if (re.match(reg, i)!=None): w_sent.append(i.lower())\n","        elif (re.match(reg_num, i) != None): w_sent.append(\"$$$$\")\n","        break\n","    a = \" \".join(w_sent)\n","    outfile.write(\"%s\\n\" %(a))\n","    br_input.append(w_sent)\n","\n","outfile.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKVavXYclo4K"},"source":["w2v_model = Word2Vec(min_count = 1, window = 5, size = 200, sample=1e-1, alpha=0.01,\n","                     min_alpha = 0.0001, negative=10, sg=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSf3RVtkn03N"},"source":["w2v_model.build_vocab(br_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ng205SttsD_d","executionInfo":{"elapsed":30548,"status":"ok","timestamp":1623467562215,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"e638aa7d-9ca5-41c1-c16e-c6baf6c05be8"},"source":["w2v_model.train(br_input, total_examples=w2v_model.corpus_count, epochs=10, report_delay=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2916980, 2916980)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiUUx_t1qz8d","executionInfo":{"elapsed":18,"status":"ok","timestamp":1623467563207,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"a2866163-3d96-4019-c3ba-76847fd3537d"},"source":["w2v_model.wv.most_similar(positive=\"bà\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('anh', 0.8594333529472351),\n"," ('bé', 0.8481131792068481),\n"," ('chị', 0.8467159271240234),\n"," ('mẹ', 0.8396469950675964),\n"," ('yingluck', 0.8348666429519653),\n"," ('con', 0.8320862054824829),\n"," ('lời', 0.8315073847770691),\n"," ('cô', 0.8233706951141357),\n"," ('cụ', 0.8202928900718689),\n"," ('vợ', 0.8182156085968018)]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zm0wz6bPq1u5","executionInfo":{"elapsed":3,"status":"ok","timestamp":1623145465087,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"c77b23ff-6551-4842-9e36-7cf198862522"},"source":["w2v_model.wv.most_similar(positive=\"xã\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('huyện', 0.9597066044807434),\n"," ('thôn', 0.888346791267395),\n"," ('thị_trấn', 0.8658595085144043),\n"," ('hà_tĩnh', 0.8563859462738037),\n"," ('phường', 0.8525856733322144),\n"," ('bắc_ninh', 0.8458022475242615),\n"," ('quận', 0.8443245887756348),\n"," ('tỉnh', 0.8420199155807495),\n"," ('nghệ_an', 0.8245270252227783),\n"," ('thanh_hoá', 0.8220493793487549)]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKjUKUBesby1","executionInfo":{"elapsed":5,"status":"ok","timestamp":1623145465953,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"4328057c-523d-4552-dd6b-071bf9232877"},"source":["w2v_model.wv.most_similar(positive=\"việt_nam\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('nhật_bản', 0.831634521484375),\n"," ('trung_quốc', 0.8109543323516846),\n"," ('hàn_quốc', 0.8017451763153076),\n"," ('châu_á', 0.7991105318069458),\n"," ('bóng_đá', 0.7960209846496582),\n"," ('quân_đội', 0.7810149788856506),\n"," ('xuất_sắc', 0.7781849503517151),\n"," ('nội_dung', 0.7760263681411743),\n"," ('châu_âu', 0.7749448418617249),\n"," ('lào', 0.7748377323150635)]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tv70xknWsjh_","executionInfo":{"elapsed":408,"status":"ok","timestamp":1623123974064,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"4ddc5fc8-99dd-46c2-c729-05d3d785be91"},"source":["w2v_model.wv.most_similar(positive=\"mùa_thị_sinh\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('hồ_thị_lệ_hà', 0.9975352883338928),\n"," ('dương_bích_nguyệt', 0.997015118598938),\n"," ('nguyễn_thị_thu_hằng', 0.9968255758285522),\n"," ('okimoto-kaewtathip', 0.996513307094574),\n"," ('hứa_thị_phấn', 0.9964773058891296),\n"," ('nguyễn_huy_hoàng', 0.9963103532791138),\n"," ('nguyễn_phương_đông', 0.996132493019104),\n"," ('hường_văn_minh', 0.996028482913971),\n"," ('khúc_thị_hoa_phượng', 0.9959829449653625),\n"," ('trần_văn_lĩnh', 0.9959742426872253)]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"VrOGIc7UtrhU"},"source":["def text2idx(sentences):\n","  idx_corpus = []\n","  for sent in sentences:\n","    idx_sent = []\n","    for w in sent:\n","      idx_sent.append(w2v_model.wv.vocab[w].index)\n","    idx_corpus.append(idx_sent)\n","  return idx_corpus\n","\n","idx_corpus = text2idx(br_input)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NALaG8lLg9pZ"},"source":["###**Get data for training word2vec BiLSTM-CRF**"]},{"cell_type":"code","metadata":{"id":"j1yO-xHZFJ_w"},"source":["datapath= '/content/drive/My Drive/nlp/vlsp 2018/data/train2.txt'\n","with open(datapath, 'rb') as f:\n","  text = f.read().decode('utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zdzkyMNEGc_S"},"source":["training_data = []\n","tag_to_idx = {} \n","idx_to_tag = {}\n","cnt = 0\n","for sent in text.split('\\n\\n'):\n","  words = []\n","  tags = []\n","  for line in sent.split('\\n'):\n","    r = line.split('\\t')\n","    if len(r) == 3: w, t, pos = r[0], r[1], r[2]\n","    words.append(w)\n","    tags.append(t)\n","    if(t not in tag_to_idx): \n","      tag_to_idx[t] = cnt\n","      idx_to_tag[cnt] = t\n","      cnt += 1\n","  training_data.append((words, tags))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y735bFwlHUqZ"},"source":["START_TAG = \"<START>\"\n","STOP_TAG = \"<STOP>\"\n","tag_to_idx[START_TAG] = cnt\n","tag_to_idx[STOP_TAG] = cnt+1\n","idx_to_tag[cnt] = START_TAG\n","idx_to_tag[cnt+1] = STOP_TAG"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"moK_6MR_zb_y"},"source":["#vec has size : 1 x tagset_size\n","def argmax(vec):\n","  _, idx = torch.max(vec, 1)\n","  return idx.item()\n","\n","def log_sum_exp(vec):\n","  \"\"\"\n","    log_sum_exp(x) = log(sum_i(exp(x_i)))\n","                   = max_i(x) - log(sum_i(exp(max_i(x) - x_i)))\n","    reference: https://nhigham.com/2021/01/05/what-is-the-log-sum-exp-function/ \n","  \"\"\"\n","  max_score = vec[0, argmax(vec)]\n","  max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n","  return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwCmLiJ70GsV"},"source":["class BiLSTM_CRF(nn.Module):\n","  def __init__(self, vocab_size, tag_to_idx, pretrained_embedding, hidden_dim):\n","    super(BiLSTM_CRF, self).__init__()\n","    self.vocab_size = vocab_size # for embedding layer - num_embeddings\n","    self.tag_to_idx = tag_to_idx\n","    self.hidden_dim = hidden_dim # hidden_dim of LSTM : dim of LSTM's output\n","    self.tagset_size = len(tag_to_idx)\n","\n","    # neural layer\n","    weight = torch.FloatTensor(pretrained_embedding)\n","    self.word_embeds = nn.Embedding.from_pretrained(weight)\n","    self.lstm = nn.LSTM(weight.shape[1], hidden_dim//2,\n","                        num_layers = 1, bidirectional=True)\n","    self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size) # like Dense\n","\n","    # init param for crf layer\n","    # transition[i][j] = p(y_i | y_j) tuc la: j -> i\n","    self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n","    self.transitions.data[tag_to_idx[START_TAG], :] = -10000 # make it impossible\n","    self.transitions.data[:, tag_to_idx[STOP_TAG]] = -10000 # make it impossible\n","\n","    #init param for lstm layer\n","    self.hidden = self.init_hidden()\n","\n","  def init_hidden(self): # ????\n","    return (torch.randn(2, 1, self.hidden_dim//2), \n","            torch.randn(2, 1, self.hidden_dim//2))\n","    \n","  def _forward_alg(self, feats):\n","    \"\"\"\n","      feats:  feats (got from lstm) of one sentence \n","    \"\"\"\n","    forward_var = torch.full((1, self.tagset_size), -10000.0)\n","    forward_var[0][self.tag_to_idx[START_TAG]] = 0.0\n","    \n","    for feat in feats: # each step\n","      alphas = []\n","      for next_tag in range(self.tagset_size):\n","        emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n","        trans_score = self.transitions[next_tag].view(1, -1)\n","        alpha_arr = forward_var + trans_score + emit_score\n","        alpha = log_sum_exp(alpha_arr).view(1)\n","        alphas.append(alpha)\n","\n","      forward_var = torch.cat(alphas).view(1, -1) # seq of tensor -> tensor\n","\n","    terminal_var = forward_var + self.transitions[tag_to_idx[STOP_TAG]]\n","    alpha = log_sum_exp(terminal_var)\n","    return alpha\n","\n","  def _get_lstm_features(self, sentence): # forward neural network\n","    self.hidden = self.init_hidden()\n","    embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n","\n","    lstm_out, self.hidden = self.lstm(embeds, self.hidden) # lstm_out: output features; out_hidden: hidden state for last step; in_hidden: initial hidden\n","    lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n","\n","    lstm_feats = self.hidden2tag(lstm_out)\n","    return lstm_feats\n","\n","  def _score_sentence(self, feats, tags):\n","    # Gives the score of a provided tag sequence\n","    score = torch.zeros(1)\n","    tags = torch.cat([torch.tensor([self.tag_to_idx[START_TAG]], dtype=torch.long), tags]) #push start tag to front of tags\n","\n","    for i, feat in enumerate(feats):\n","      score = score + \\\n","            self.transitions[tags[i+1], tags[i]] + \\\n","            feat[tags[i+1]]\n","\n","    score = score + self.transitions[self.tag_to_idx[STOP_TAG], tags[-1]]\n","    return score\n","\n","  def _viterbi_decode(self, feats):\n","    backpointers = []\n","    forward_var = torch.full((1, self.tagset_size), -10000.0)\n","    forward_var[0][self.tag_to_idx[START_TAG]] = 0.0\n","\n","    for feat in feats:\n","      bptrs = [] # hold backpointers for tags at this step\n","      alphas = []\n","      for next_tag in range(self.tagset_size):\n","        trans_score = self.transitions[next_tag]\n","        scores = forward_var + trans_score\n","        best_tag_id = argmax(scores)\n","        bptrs.append(best_tag_id)\n","        alphas.append(scores[0][best_tag_id].view(1))\n","\n","      forward_var = (torch.cat(alphas) + feat).view(1, -1) #thu sua cho nay xem sao\n","      backpointers.append(bptrs)\n","\n","    terminal_var = forward_var + \\\n","                self.transitions[self.tag_to_idx[STOP_TAG]]\n","    best_tag_id = argmax(terminal_var)\n","    path_score = terminal_var[0][best_tag_id]\n","\n","    best_path = [best_tag_id]\n","    for bpters_t in reversed(backpointers):\n","      best_tag_id = bpters_t[best_tag_id]\n","      best_path.append(best_tag_id)\n","\n","    start = best_path.pop()\n","    assert  start == self.tag_to_idx[START_TAG]\n","    best_path.reverse()\n","    return path_score, best_path\n","\n","  def neg_log_likelihood(self, sentence, tags):\n","    feats = self._get_lstm_features(sentence)\n","    forward_score = self._forward_alg(feats) # ~ z\n","    gold_score = self._score_sentence(feats, tags)\n","    return forward_score - gold_score\n","\n","  def forward(self,sentence):\n","    lstm_feats = self._get_lstm_features(sentence)\n","    score, tag_seq = self._viterbi_decode(lstm_feats)\n","    return score, tag_seq\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2i5aY3O5WbIs","executionInfo":{"elapsed":7,"status":"ok","timestamp":1623336346828,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"d1494a42-5b3e-49e6-9d96-4b7aa5dbae60"},"source":["w2v_model.wv.index2word[1454]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'tiếp_nhận'"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"zcvuldppAMaJ"},"source":["EMBEDDING_DIM = 200\n","def word2idx(w):\n","  w = w.lower()\n","  if (w in w2v_model.wv.vocab):\n","    return w2v_model.wv.vocab[w].index\n","  else:\n","    return w2v_model.wv.vocab['$$$$'].index\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGrZMqMGGzlp"},"source":["def prepare_sequence(seq):\n","  \"\"\"\n","    convert sentence to idxs sequence (a tensor of idx)\n","  \"\"\"\n","  idxs = [word2idx(w) for w in seq]\n","  return torch.tensor(idxs, dtype=torch.long) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQdGZfeRYheT","executionInfo":{"elapsed":451,"status":"ok","timestamp":1623338072342,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"49282851-24f4-45de-fc43-c5893c7f1bba"},"source":["torch.FloatTensor(w2v_model.wv.vectors).shape[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15709"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0Akb0ZsG9pk","executionInfo":{"elapsed":417,"status":"ok","timestamp":1623336279716,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"707aa90a-d5bb-4d79-a82b-a9412de47a08"},"source":["prepare_sequence(training_data[0][0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1454,   84,    0,  150,    0,    0,    0,   36,  866,    0,  392,  551,\n","        1726,  303,  915,    2,    0,  582,  456, 1778, 1919,   37,    0, 2698,\n","           0,   15,  880, 3006,    0,    0,  392,  551,  801,  668,   70,  616,\n","          76,    0,  107,   24,    0,   26,    0,    0,  775,  269,    0,  582,\n","        2698,  103,  953,    1,  582, 2698,   66, 1852,    0,  765,   76,  106,\n","           0,   84,    0,  150,    0,    0])"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"ERYU2OuxH-fV"},"source":["y_trivial = [0]*len(training_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_V3aDVbH7sj"},"source":["train_data, val_data,_ , _ = train_test_split(training_data, y_trivial, test_size = 0.2, random_state=26)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRL2hkkFJWo0"},"source":["HIDDEN_DIM = 32\n","model = BiLSTM_CRF(len(w2v_model.wv.vocab), tag_to_idx, w2v_model.wv.vectors, HIDDEN_DIM)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyNsgokDGlOP","executionInfo":{"elapsed":329,"status":"ok","timestamp":1623467572125,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"4c8661ae-bff9-40dc-9bcc-0127e87cc42b"},"source":["with torch.no_grad():\n","  precheck_sent = prepare_sequence(training_data[0][0])\n","  precheck_tags = torch.tensor([tag_to_idx[t] for t in training_data[0][1]], dtype=torch.long)\n","  print(len(model(precheck_sent)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["66\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pg6pN6_ZH0yX","executionInfo":{"elapsed":15977674,"status":"ok","timestamp":1623483573340,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"cc52cbc7-0c02-4933-abc1-2dc2b24524fe"},"source":["# Make sure prepare_sequence from earlier in the LSTM section is loaded\n","for epoch in range(10):\n","    i = 0\n","    for sentence, tags in train_data:\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance         \n","        model.zero_grad()\n","        i+=1\n","        if(i%100) == 0: print(i)\n","        # Step 2. Get our inputs ready for the network, that is,\n","        # turn them into Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence)\n","        targets = torch.tensor([tag_to_idx[t] for t in tags], dtype=torch.long)\n","\n","        # Step 3. Run our forward pass.\n","        loss = model.neg_log_likelihood(sentence_in, targets)\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        # calling optimizer.step()\n","        loss.backward()\n","        optimizer.step()\n","    preY_val = []\n","\n","    with torch.no_grad():\n","        for sent in X_val:\n","            precheck_sent = prepare_sequence(sent)\n","            preY_val.append(model(precheck_sent)[1])\n","    y_pred = []\n","    for n_sent in preY_val:\n","        t_sent = []\n","        for nt in n_sent:\n","            t_sent.append(idx_to_tag[nt])\n","        y_pred.append(t_sent)\n","    evaluate(y_pred, Y_val)\n","    torch.save(model.state_dict(), '/content/drive/My Drive/nlp/vlsp 2018/model/word2vecBiLSTM')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  883 \t NE_sys:  1314 \t NE_ref:  4112\n","F1_score:  0.32546995945447843\n","Recall on Nested Entities:  0.28852459016393445\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  986 \t NE_sys:  1529 \t NE_ref:  4112\n","F1_score:  0.34958340719730546\n","Recall on Nested Entities:  0.33114754098360655\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1189 \t NE_sys:  1790 \t NE_ref:  4112\n","F1_score:  0.4029142663503897\n","Recall on Nested Entities:  0.3836065573770492\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1160 \t NE_sys:  1770 \t NE_ref:  4112\n","F1_score:  0.3944236654199252\n","Recall on Nested Entities:  0.3704918032786885\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1179 \t NE_sys:  1670 \t NE_ref:  4112\n","F1_score:  0.40781736423382914\n","Recall on Nested Entities:  0.3704918032786885\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1346 \t NE_sys:  1966 \t NE_ref:  4112\n","F1_score:  0.44290885159591975\n","Recall on Nested Entities:  0.42295081967213116\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1438 \t NE_sys:  2104 \t NE_ref:  4112\n","F1_score:  0.4626769626769627\n","Recall on Nested Entities:  0.4491803278688525\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1485 \t NE_sys:  2158 \t NE_ref:  4112\n","F1_score:  0.47368421052631576\n","Recall on Nested Entities:  0.4672131147540984\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1568 \t NE_sys:  2295 \t NE_ref:  4112\n","F1_score:  0.489464648041205\n","Recall on Nested Entities:  0.4934426229508197\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1629 \t NE_sys:  2382 \t NE_ref:  4112\n","F1_score:  0.5016938712657838\n","Recall on Nested Entities:  0.4918032786885246\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u_AR0lhfP7q-"},"source":["import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WUYb5FSTPTxp","outputId":"c67dddeb-662e-4885-df02-18c24149aab7"},"source":["# Make sure prepare_sequence from earlier in the LSTM section is loaded\n","for epoch in range(10):\n","    i = 0\n","    random.shuffle(train_data)\n","    for sentence, tags in train_data:\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance         \n","        model.zero_grad()\n","        i+=1\n","        if(i%100) == 0: print(i)\n","        # Step 2. Get our inputs ready for the network, that is,\n","        # turn them into Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence)\n","        targets = torch.tensor([tag_to_idx[t] for t in tags], dtype=torch.long)\n","\n","        # Step 3. Run our forward pass.\n","        loss = model.neg_log_likelihood(sentence_in, targets)\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        # calling optimizer.step()\n","        loss.backward()\n","        optimizer.step()\n","    preY_val = []\n","\n","    with torch.no_grad():\n","        for sent in X_val:\n","            precheck_sent = prepare_sequence(sent)\n","            preY_val.append(model(precheck_sent)[1])\n","    y_pred = []\n","    for n_sent in preY_val:\n","        t_sent = []\n","        for nt in n_sent:\n","            t_sent.append(idx_to_tag[nt])\n","        y_pred.append(t_sent)\n","    evaluate(y_pred, Y_val)\n","    torch.save(model.state_dict(), '/content/drive/My Drive/nlp/vlsp 2018/model/word2vecBiLSTM_shuffle')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1414 \t NE_sys:  1906 \t NE_ref:  4112\n","F1_score:  0.46992356264539714\n","Recall on Nested Entities:  0.4819672131147541\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1495 \t NE_sys:  1989 \t NE_ref:  4112\n","F1_score:  0.4900835928536305\n","Recall on Nested Entities:  0.5344262295081967\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1723 \t NE_sys:  2424 \t NE_ref:  4112\n","F1_score:  0.5272337821297429\n","Recall on Nested Entities:  0.5508196721311476\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1755 \t NE_sys:  2609 \t NE_ref:  4112\n","F1_score:  0.5222437137330753\n","Recall on Nested Entities:  0.5163934426229508\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2138 \t NE_sys:  3861 \t NE_ref:  4112\n","F1_score:  0.5363100464066225\n","Recall on Nested Entities:  0.6245901639344262\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2060 \t NE_sys:  3461 \t NE_ref:  4112\n","F1_score:  0.5440380298428628\n","Recall on Nested Entities:  0.5655737704918032\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1734 \t NE_sys:  2322 \t NE_ref:  4112\n","F1_score:  0.5390115013988188\n","Recall on Nested Entities:  0.5524590163934426\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1846 \t NE_sys:  2895 \t NE_ref:  4112\n","F1_score:  0.5269016697588126\n","Recall on Nested Entities:  0.5704918032786885\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1908 \t NE_sys:  2758 \t NE_ref:  4112\n","F1_score:  0.5554585152838428\n","Recall on Nested Entities:  0.5540983606557377\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2051 \t NE_sys:  3087 \t NE_ref:  4112\n","F1_score:  0.5698013613001806\n","Recall on Nested Entities:  0.6114754098360655\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XGRWJIMAhJj6"},"source":["###**Evaluation**"]},{"cell_type":"code","metadata":{"id":"kAuSJjbWX_Fs"},"source":["X_val, Y_val = [], []\n","for sent in val_data:\n","  X_val.append(sent[0])\n","  Y_val.append(sent[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mD7QWZPAt9WJ"},"source":["X_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvF8qiEiYALh"},"source":["preY_val = []\n","\n","with torch.no_grad():\n","    for sent in X_val:\n","      precheck_sent = prepare_sequence(sent)\n","      preY_val.append(model(precheck_sent)[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dv42v0y6YI6g"},"source":["y_pred = []\n","for n_sent in preY_val:\n","  t_sent = []\n","  for nt in n_sent:\n","    t_sent.append(idx_to_tag[nt])\n","  y_pred.append(t_sent)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsSgMb2Jedtg"},"source":["y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xleX81IQYMzw"},"source":["def isOpen(tag):\n","  return tag[0] == 'B'\n","\n","def isCloseOf(tag, open_tag):\n","  if tag == \"O\": return True\n","  if(len(tag.split()) < len(open_tag.split())):\n","    return True\n","  # case same len\n","  if(tag[0] == 'B' or tag[2:5] != open_tag[2:5]) and (len(tag.split()) == len(open_tag.split())):\n","    return True\n","  return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGoUpQR4YSPl","executionInfo":{"elapsed":338,"status":"ok","timestamp":1623467581689,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"07c1fe63-5a24-41d5-9f43-0b46452b5ce0"},"source":["def getEntSpanSet(sent):\n","  \"\"\"\n","    return set of ent spans & set of nested ent spans\n","  \"\"\"\n","  stack = []\n","  ent_spans = set()\n","  nent_spans = set()\n","  isNested = False\n","  for i, w in enumerate(sent):\n","    if len(stack) > 1: isNested = True\n","\n","    while (stack and isCloseOf(w, stack[-1][0]) and stack[-1][1] != i):\n","      tag, begin = stack[-1][0][2:5], stack[-1][1]\n","      ent_spans.add((tag, begin, i))\n","      if isNested: nent_spans.add((tag, begin, i))\n","      stack.pop()\n","\n","    if not stack : isNested = False\n","    if isOpen(w):\n","      stack.append((w, i))\n","\n","  while stack:\n","    tag, begin = stack[-1][0][2:5], stack[-1][1]\n","    ent_spans.add((tag, begin, len(sent)))\n","    stack.pop()\n","  return ent_spans, nent_spans\n","sent = ['O', 'O', 'O', 'B-ORG', 'I-ORG', 'B-LOC I-ORG', 'B-ORG', 'B-LOC I-ORG', 'I-ORG', 'B-ORG', 'B-LOC I-ORG', 'B-ORG', 'B-LOC I-ORG', 'B-PER I-ORG', 'O', 'O', 'B-PER']\n","getEntSpanSet(sent)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({('LOC', 5, 6),\n","  ('LOC', 7, 8),\n","  ('LOC', 10, 11),\n","  ('LOC', 12, 13),\n","  ('ORG', 3, 6),\n","  ('ORG', 6, 9),\n","  ('ORG', 9, 11),\n","  ('ORG', 11, 14),\n","  ('PER', 13, 14),\n","  ('PER', 16, 17)},\n"," {('LOC', 5, 6),\n","  ('LOC', 7, 8),\n","  ('LOC', 10, 11),\n","  ('LOC', 12, 13),\n","  ('ORG', 3, 6),\n","  ('ORG', 6, 9),\n","  ('ORG', 9, 11),\n","  ('ORG', 11, 14),\n","  ('PER', 13, 14)})"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"evO59nOuYUtb"},"source":["def evaluateSent(sent_pred, sent_true):\n","  \"\"\"\n","    return the num of found ents, the num of found nested ents\n","  \"\"\"\n","  pred_ents, pred_nents = getEntSpanSet(sent_pred)\n","  true_ents, true_nents = getEntSpanSet(sent_true)\n","  ne_ref = len(true_ents)\n","  ne_sys = len(pred_ents)\n","  ne_true = 0\n","  nen_ref = len(true_nents)\n","  nen_true = 0\n","  for ent in pred_ents:\n","    if ent in true_ents:\n","      ne_true += 1\n","    if ent in true_nents:\n","      nen_true += 1\n","  return ne_ref, ne_sys, ne_true, nen_ref, nen_true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAsLS_F5YWpD"},"source":["def evaluate(y_pred, y_true):\n","  NE_ref = 0\n","  NE_sys = 0\n","  NE_true = 0\n","  NEN_ref = 0\n","  NEN_true = 0\n","\n","  for s in range(len(y_true)):\n","    sent_pred, sent_true = y_pred[s], y_true[s]\n","    ne_ref, ne_sys, ne_true, nen_ref, nen_true = evaluateSent(sent_pred, sent_true)\n","    NE_true += ne_true\n","    NE_sys += ne_sys\n","    NE_ref += ne_ref\n","    NEN_ref += nen_ref\n","    NEN_true += nen_true\n","\n","  print(\"NE_true: \", NE_true, \"\\t NE_sys: \", NE_sys, \"\\t NE_ref: \", NE_ref)\n","  p = NE_true / NE_sys\n","  r = NE_true / NE_ref\n","  f1 = 2*p*r / (p+r)\n","  print(\"F1_score: \", f1)\n","  NEN_recall = NEN_true/NEN_ref\n","  print(\"Recall on Nested Entities: \", NEN_recall)\n","  return f1, NEN_recall"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzcxeL9BYXjC","executionInfo":{"elapsed":347,"status":"ok","timestamp":1623342751623,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"9e56e270-b989-4329-cb03-8512b7c802a5"},"source":["evaluate(y_pred, Y_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NE_true:  1214 \t NE_sys:  1792 \t NE_ref:  4112\n","F1_score:  0.41124661246612465\n","Recall on Nested Entities:  0.3704918032786885\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.41124661246612465, 0.3704918032786885)"]},"metadata":{"tags":[]},"execution_count":69}]}]}