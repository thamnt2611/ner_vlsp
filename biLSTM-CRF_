{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"biLSTM-CRF ","provenance":[],"authorship_tag":"ABX9TyP61/Lhq7AtH8R3vYz9btH2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"agWI8oowFLjw","executionInfo":{"status":"ok","timestamp":1624095282817,"user_tz":-420,"elapsed":33042,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"}},"outputId":"f6600bcc-e8f4-41cf-cd52-8b0d55c4c4c4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8PrWRGWFLuZ"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","torch.manual_seed(1)\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SfSMQCGmFFKY"},"source":["### **Process Text**"]},{"cell_type":"code","metadata":{"id":"j1yO-xHZFJ_w"},"source":["datapath= '/content/drive/My Drive/nlp/vlsp 2018/data/train2.txt'\n","with open(datapath, 'rb') as f:\n","  text = f.read().decode('utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zdzkyMNEGc_S"},"source":["training_data = []\n","tag_to_idx = {} \n","idx_to_tag = {}\n","cnt = 0\n","for sent in text.split('\\n\\n'):\n","  words = []\n","  tags = []\n","  for line in sent.split('\\n'):\n","    r = line.split('\\t')\n","    if len(r) == 3: w, t, pos = r[0], r[1], r[2]\n","    words.append(w)\n","    tags.append(t)\n","    if(t not in tag_to_idx): \n","      tag_to_idx[t] = cnt\n","      idx_to_tag[cnt] = t\n","      cnt += 1\n","  training_data.append((words, tags))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y735bFwlHUqZ"},"source":["START_TAG = \"<START>\"\n","STOP_TAG = \"<STOP>\"\n","tag_to_idx[START_TAG] = cnt\n","tag_to_idx[STOP_TAG] = cnt+1\n","idx_to_tag[cnt] = START_TAG\n","idx_to_tag[cnt+1] = STOP_TAG"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1w19IlLEJi-K","executionInfo":{"status":"ok","timestamp":1624095291063,"user_tz":-420,"elapsed":18,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"}},"outputId":"1b21a6f4-1c24-4f28-b125-17825ca26b6e"},"source":["tag_to_idx"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'<START>': 28,\n"," '<STOP>': 29,\n"," 'B-LOC': 1,\n"," 'B-LOC B-ORG': 19,\n"," 'B-LOC I-LOC': 15,\n"," 'B-LOC I-LOC I-ORG': 20,\n"," 'B-LOC I-MIS': 25,\n"," 'B-LOC I-ORG': 5,\n"," 'B-LOC I-ORG I-ORG': 10,\n"," 'B-MIS': 11,\n"," 'B-ORG': 3,\n"," 'B-ORG I-ORG': 8,\n"," 'B-ORG I-ORG I-ORG': 18,\n"," 'B-PER': 7,\n"," 'B-PER B-ORG': 26,\n"," 'B-PER I-LOC': 24,\n"," 'B-PER I-ORG': 17,\n"," 'B-PER I-ORG I-ORG': 23,\n"," 'B-RGA': 22,\n"," 'I-LOC': 2,\n"," 'I-LOC I-LOC': 16,\n"," 'I-LOC I-LOC I-ORG': 21,\n"," 'I-LOC I-ORG': 6,\n"," 'I-LOC I-ORG I-ORG': 13,\n"," 'I-MIS': 12,\n"," 'I-ORG': 4,\n"," 'I-ORG I-ORG': 9,\n"," 'I-PER': 14,\n"," 'I-PER I-ORG': 27,\n"," 'O': 0}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7jWgQivrStI","executionInfo":{"elapsed":1348,"status":"ok","timestamp":1621093072085,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"ec26e93b-561d-49bf-9e2a-c344e90655bc"},"source":["idx_to_tag"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'O',\n"," 1: 'B-LOC',\n"," 2: 'I-LOC',\n"," 3: 'B-ORG',\n"," 4: 'I-ORG',\n"," 5: 'B-LOC I-ORG',\n"," 6: 'I-LOC I-ORG',\n"," 7: 'B-PER',\n"," 8: 'B-ORG I-ORG',\n"," 9: 'I-ORG I-ORG',\n"," 10: 'B-LOC I-ORG I-ORG',\n"," 11: 'B-MIS',\n"," 12: 'I-MIS',\n"," 13: 'I-LOC I-ORG I-ORG',\n"," 14: 'I-PER',\n"," 15: 'B-LOC I-LOC',\n"," 16: 'I-LOC I-LOC',\n"," 17: 'B-PER I-ORG',\n"," 18: 'B-ORG I-ORG I-ORG',\n"," 19: 'B-LOC B-ORG',\n"," 20: 'B-LOC I-LOC I-ORG',\n"," 21: 'I-LOC I-LOC I-ORG',\n"," 22: 'B-RGA',\n"," 23: 'B-PER I-ORG I-ORG',\n"," 24: 'B-PER I-LOC',\n"," 25: 'B-LOC I-MIS',\n"," 26: 'B-PER B-ORG',\n"," 27: 'I-PER I-ORG',\n"," 28: '<START>',\n"," 29: '<STOP>'}"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"l-6FgsY5FAp-"},"source":["### **Build Model**"]},{"cell_type":"code","metadata":{"id":"HOEVy2sVG9Y9"},"source":["#vec has size : 1 x tagset_size\n","def argmax(vec):\n","  _, idx = torch.max(vec, 1)\n","  return idx.item()\n","\n","def prepare_sequence(seq, to_idx):\n","  \"\"\"\n","    convert sentence to idxs sequence (a tensor of idx)\n","  \"\"\"\n","  idxs = [to_idx[w] for w in seq]\n","  return torch.tensor(idxs, dtype=torch.long) \n","\n","def log_sum_exp(vec):\n","  \"\"\"\n","    log_sum_exp(x) = log(sum_i(exp(x_i)))\n","                   = max_i(x) - log(sum_i(exp(max_i(x) - x_i)))\n","    reference: https://nhigham.com/2021/01/05/what-is-the-log-sum-exp-function/ \n","  \"\"\"\n","  max_score = vec[0, argmax(vec)]\n","  max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n","  return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rw0fdeul5FBP"},"source":["class BiLSTM_CRF(nn.Module):\n","  def __init__(self, vocab_size, tag_to_idx, embedding_dim, hidden_dim):\n","    super(BiLSTM_CRF, self).__init__()\n","    self.vocab_size = vocab_size # for embedding layer - num_embeddings\n","    self.embedding_dim = embedding_dim # output_dim of embedding layer\n","    self.tag_to_idx = tag_to_idx\n","    self.hidden_dim = hidden_dim # hidden_dim of LSTM : dim of LSTM's output\n","    self.tagset_size = len(tag_to_idx)\n","\n","    # neural layer\n","    self.word_embeds = nn.Embedding(vocab_size, embedding_dim) \n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim//2,\n","                        num_layers = 1, bidirectional=True)\n","    self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size) # like Dense\n","\n","    # init param for crf layer\n","    # transition[i][j] = p(y_i | y_j) tuc la: j -> i\n","    self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n","    self.transitions.data[tag_to_idx[START_TAG], :] = -10000 # make it impossible\n","    self.transitions.data[:, tag_to_idx[STOP_TAG]] = -10000 # make it impossible\n","\n","    #init param for lstm layer\n","    self.hidden = self.init_hidden()\n","\n","  def init_hidden(self): # ????\n","    return (torch.randn(2, 1, self.hidden_dim//2), \n","            torch.randn(2, 1, self.hidden_dim//2))\n","    \n","  def _forward_alg(self, feats):\n","    \"\"\"\n","      feats:  feats (got from lstm) of one sentence \n","    \"\"\"\n","    forward_var = torch.full((1, self.tagset_size), -10000.0)\n","    forward_var[0][self.tag_to_idx[START_TAG]] = 0.0\n","    \n","    for feat in feats: # each step\n","      alphas = []\n","      for next_tag in range(self.tagset_size):\n","        emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n","        trans_score = self.transitions[next_tag].view(1, -1)\n","        alpha_arr = forward_var + trans_score + emit_score\n","        alpha = log_sum_exp(alpha_arr).view(1)\n","        alphas.append(alpha)\n","\n","      forward_var = torch.cat(alphas).view(1, -1) # seq of tensor -> tensor\n","\n","    terminal_var = forward_var + self.transitions[tag_to_idx[STOP_TAG]]\n","    alpha = log_sum_exp(terminal_var)\n","    return alpha\n","\n","  def _get_lstm_features(self, sentence): # forward neural network\n","    self.hidden = self.init_hidden()\n","    embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n","\n","    lstm_out, self.hidden = self.lstm(embeds, self.hidden) # lstm_out: output features; out_hidden: hidden state for last step; in_hidden: initial hidden\n","    lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n","\n","    lstm_feats = self.hidden2tag(lstm_out)\n","    return lstm_feats\n","\n","  def _score_sentence(self, feats, tags):\n","    # Gives the score of a provided tag sequence\n","    score = torch.zeros(1)\n","    tags = torch.cat([torch.tensor([self.tag_to_idx[START_TAG]], dtype=torch.long), tags]) #push start tag to front of tags\n","\n","    for i, feat in enumerate(feats):\n","      score = score + \\\n","            self.transitions[tags[i+1], tags[i]] + \\\n","            feat[tags[i+1]]\n","\n","    score = score + self.transitions[self.tag_to_idx[STOP_TAG], tags[-1]]\n","    return score\n","\n","  def _viterbi_decode(self, feats):\n","    backpointers = []\n","    forward_var = torch.full((1, self.tagset_size), -10000.0)\n","    forward_var[0][self.tag_to_idx[START_TAG]] = 0.0\n","\n","    for feat in feats:\n","      bptrs = [] # hold backpointers for tags at this step\n","      alphas = []\n","      for next_tag in range(self.tagset_size):\n","        trans_score = self.transitions[next_tag]\n","        scores = forward_var + trans_score\n","        best_tag_id = argmax(scores)\n","        bptrs.append(best_tag_id)\n","        alphas.append(scores[0][best_tag_id].view(1))\n","\n","      forward_var = (torch.cat(alphas) + feat).view(1, -1) #thu sua cho nay xem sao\n","      backpointers.append(bptrs)\n","\n","    terminal_var = forward_var + \\\n","                self.transitions[self.tag_to_idx[STOP_TAG]]\n","    best_tag_id = argmax(terminal_var)\n","    path_score = terminal_var[0][best_tag_id]\n","\n","    best_path = [best_tag_id]\n","    for bpters_t in reversed(backpointers):\n","      best_tag_id = bpters_t[best_tag_id]\n","      best_path.append(best_tag_id)\n","\n","    start = best_path.pop()\n","    assert  start == self.tag_to_idx[START_TAG]\n","    best_path.reverse()\n","    return path_score, best_path\n","\n","  def neg_log_likelihood(self, sentence, tags):\n","    feats = self._get_lstm_features(sentence)\n","    forward_score = self._forward_alg(feats) # ~ z\n","    gold_score = self._score_sentence(feats, tags)\n","    return forward_score - gold_score\n","\n","  def forward(self,sentence):\n","    lstm_feats = self._get_lstm_features(sentence)\n","    score, tag_seq = self._viterbi_decode(lstm_feats)\n","    return score, tag_seq\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Z_5yN2DF9Ef"},"source":["EMBEDDING_DIM = 10\n","HIDDEN_DIM = 32\n","\n","word_to_ix = {}\n","for sentence, tags in training_data:\n","    for word in sentence:\n","        if word not in word_to_ix:\n","            word_to_ix[word] = len(word_to_ix)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1nh9Y0gaHq7"},"source":["model = BiLSTM_CRF(len(word_to_ix), tag_to_idx, EMBEDDING_DIM, HIDDEN_DIM)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fh1q4aTUave4","executionInfo":{"status":"ok","timestamp":1624068366147,"user_tz":-420,"elapsed":503,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"}},"outputId":"c91d6119-f591-4419-a286-0af3a8cdf343"},"source":["with torch.no_grad():\n","  precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n","  precheck_tags = torch.tensor([tag_to_idx[t] for t in training_data[0][1]], dtype=torch.long)\n","  print(model(precheck_sent))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(tensor(144.8599), [2, 9, 24, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 3, 18, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 3, 12, 23, 8, 9, 24, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNaRgR-uLdC4","executionInfo":{"elapsed":300,"status":"ok","timestamp":1623381866770,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"},"user_tz":-420},"outputId":"64a1f619-322e-4401-bbd5-ced1c79329f6"},"source":["len(training_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14123"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"6v-3tvn_UKzu"},"source":["y_trivial = [0]*len(training_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-Wxg-AMTbwM"},"source":["train_data, val_data,_ , _ = train_test_split(training_data, y_trivial, test_size = 0.2, random_state=26)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KgdSaiLtUYFE","executionInfo":{"status":"ok","timestamp":1624068376124,"user_tz":-420,"elapsed":5,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"}},"outputId":"fcd403e0-d576-4ba1-acf2-c98e58207722"},"source":["print(len(train_data), len(val_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["11298 2825\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qhZFB7kQpxUv"},"source":["X_val, Y_val = [], []\n","for sent in val_data:\n","  X_val.append(sent[0])\n","  Y_val.append(sent[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20Ce5uAxP4Jg"},"source":["def isOpen(tag):\n","  return tag[0] == 'B'\n","\n","def isCloseOf(tag, open_tag):\n","  if tag == \"O\": return True\n","  if(len(tag.split()) < len(open_tag.split())):\n","    return True\n","  # case same len\n","  if(tag[0] == 'B' or tag[2:5] != open_tag[2:5]) and (len(tag.split()) == len(open_tag.split())):\n","    return True\n","  return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qU9b-ptgPYd2","executionInfo":{"status":"ok","timestamp":1624095310540,"user_tz":-420,"elapsed":2,"user":{"displayName":"Tham Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxZ_ql-1gCzuLxIeUVOx9io3GhzSOnRLSxtrfjWQ=s64","userId":"08115431282085785356"}},"outputId":"944a89f3-2914-41ba-b0f1-2aa4fec1d93f"},"source":["def getEntSpanSet(sent):\n","  \"\"\"\n","    return set of ent spans & set of nested ent spans\n","  \"\"\"\n","  stack = []\n","  ent_spans = set()\n","  nent_spans = set()\n","  isNested = False\n","  for i, w in enumerate(sent):\n","    if len(stack) > 1: isNested = True\n","\n","    while (stack and isCloseOf(w, stack[-1][0]) and stack[-1][1] != i):\n","      tag, begin = stack[-1][0][2:5], stack[-1][1]\n","      ent_spans.add((tag, begin, i))\n","      if isNested: nent_spans.add((tag, begin, i))\n","      stack.pop()\n","\n","    if not stack : isNested = False\n","    if isOpen(w):\n","      stack.append((w, i))\n","\n","  while stack:\n","    tag, begin = stack[-1][0][2:5], stack[-1][1]\n","    ent_spans.add((tag, begin, len(sent)))\n","    stack.pop()\n","  return ent_spans, nent_spans\n","sent = ['O', 'O', 'O', 'B-ORG', 'I-ORG', 'B-LOC I-ORG', 'B-ORG', 'B-LOC I-ORG', 'I-ORG', 'B-ORG', 'B-LOC I-ORG', 'B-ORG', 'B-LOC I-ORG', 'B-PER I-ORG', 'O', 'O', 'B-PER']\n","getEntSpanSet(sent)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({('LOC', 5, 6),\n","  ('LOC', 7, 8),\n","  ('LOC', 10, 11),\n","  ('LOC', 12, 13),\n","  ('ORG', 3, 6),\n","  ('ORG', 6, 9),\n","  ('ORG', 9, 11),\n","  ('ORG', 11, 14),\n","  ('PER', 13, 14),\n","  ('PER', 16, 17)},\n"," {('LOC', 5, 6),\n","  ('LOC', 7, 8),\n","  ('LOC', 10, 11),\n","  ('LOC', 12, 13),\n","  ('ORG', 3, 6),\n","  ('ORG', 6, 9),\n","  ('ORG', 9, 11),\n","  ('ORG', 11, 14),\n","  ('PER', 13, 14)})"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"oBzOantfJ58u"},"source":["def evaluateSent(sent_pred, sent_true):\n","  \"\"\"\n","    return the num of found ents, the num of found nested ents\n","  \"\"\"\n","  pred_ents, pred_nents = getEntSpanSet(sent_pred)\n","  true_ents, true_nents = getEntSpanSet(sent_true)\n","  ne_ref = len(true_ents)\n","  ne_sys = len(pred_ents)\n","  ne_true = 0\n","  nen_ref = len(true_nents)\n","  nen_true = 0\n","  for ent in pred_ents:\n","    if ent in true_ents:\n","      ne_true += 1\n","    if ent in true_nents:\n","      nen_true += 1\n","  return ne_ref, ne_sys, ne_true, nen_ref, nen_true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGw40ye2Ks3u"},"source":["def evaluate(y_pred, y_true):\n","  NE_ref = 0\n","  NE_sys = 0\n","  NE_true = 0\n","  NEN_ref = 0\n","  NEN_true = 0\n","\n","  for s in range(len(y_true)):\n","    sent_pred, sent_true = y_pred[s], y_true[s]\n","    ne_ref, ne_sys, ne_true, nen_ref, nen_true = evaluateSent(sent_pred, sent_true)\n","    NE_true += ne_true\n","    NE_sys += ne_sys\n","    NE_ref += ne_ref\n","    NEN_ref += nen_ref\n","    NEN_true += nen_true\n","\n","  print(\"NE_true: \", NE_true, \"\\t NE_sys: \", NE_sys, \"\\t NE_ref: \", NE_ref)\n","  p = NE_true / NE_sys\n","  r = NE_true / NE_ref\n","  f1 = 2*p*r / (p+r)\n","  print(\"F1_score: \", f1)\n","  NEN_recall = NEN_true/NEN_ref\n","  print(\"Recall on Nested Entities: \", NEN_recall)\n","  return f1, NEN_recall"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Xt2-cebreKZs","outputId":"c57117b7-916b-4583-d14e-551df3f06086"},"source":["# Make sure prepare_sequence from earlier in the LSTM section is loaded\n","for epoch in range(10):\n","    i = 0\n","    for sentence, tags in train_data:\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance         \n","        model.zero_grad()\n","        i+=1\n","        if(i%100) == 0: print(i) \n","        # Step 2. Get our inputs ready for the network, that is,\n","        # turn them into Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence, word_to_ix)\n","        targets = torch.tensor([tag_to_idx[t] for t in tags], dtype=torch.long)\n","\n","        # Step 3. Run our forward pass.\n","        loss = model.neg_log_likelihood(sentence_in, targets)\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        # calling optimizer.step()\n","        loss.backward()\n","        optimizer.step()\n","    preY_val = []\n","\n","    with torch.no_grad():\n","        for sent in X_val:\n","            precheck_sent = prepare_sequence(sent, word_to_ix)\n","            preY_val.append(model(precheck_sent)[1])\n","    y_pred = []\n","    for n_sent in preY_val:\n","        t_sent = []\n","        for nt in n_sent:\n","            t_sent.append(idx_to_tag[nt])\n","        y_pred.append(t_sent)\n","    evaluate(y_pred, Y_val)\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1011 \t NE_sys:  1553 \t NE_ref:  4112\n","F1_score:  0.35692850838481904\n","Recall on Nested Entities:  0.3622950819672131\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1482 \t NE_sys:  2163 \t NE_ref:  4112\n","F1_score:  0.47235059760956183\n","Recall on Nested Entities:  0.4934426229508197\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1796 \t NE_sys:  2606 \t NE_ref:  4112\n","F1_score:  0.5346829413515927\n","Recall on Nested Entities:  0.5540983606557377\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2091 \t NE_sys:  2991 \t NE_ref:  4112\n","F1_score:  0.5887653104322117\n","Recall on Nested Entities:  0.601639344262295\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2264 \t NE_sys:  3160 \t NE_ref:  4112\n","F1_score:  0.6226622662266227\n","Recall on Nested Entities:  0.639344262295082\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2402 \t NE_sys:  3275 \t NE_ref:  4112\n","F1_score:  0.6503316637335861\n","Recall on Nested Entities:  0.6672131147540984\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2504 \t NE_sys:  3421 \t NE_ref:  4112\n","F1_score:  0.6648081773529801\n","Recall on Nested Entities:  0.680327868852459\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4MS8R9psqkrr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b237f92-1d92-46c5-fd04-4f6aae7b8935"},"source":["# Make sure prepare_sequence from earlier in the LSTM section is loaded\n","f1_scores = []\n","NEN_recalls = []\n","for epoch in range(10):\n","    i = 0\n","    for sentence, tags in train_data:\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance         \n","        model.zero_grad()\n","        i+=1\n","        if(i%100) == 0: print(i)\n","        # Step 2. Get our inputs ready for the network, that is,\n","        # turn them into Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence, word_to_ix)\n","        targets = torch.tensor([tag_to_idx[t] for t in tags], dtype=torch.long)\n","\n","        # Step 3. Run our forward pass.\n","        loss = model.neg_log_likelihood(sentence_in, targets)\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        # calling optimizer.step()\n","        loss.backward()\n","        optimizer.step()\n","    preY_val = []\n","\n","    with torch.no_grad():\n","        for sent in X_val:\n","            precheck_sent = prepare_sequence(sent, word_to_ix)\n","            preY_val.append(model(precheck_sent)[1])\n","    y_pred = []\n","    for n_sent in preY_val:\n","        t_sent = []\n","        for nt in n_sent:\n","            t_sent.append(idx_to_tag[nt])\n","        y_pred.append(t_sent)\n","    f1, recall = evaluate(y_pred, Y_val)\n","    f1_scores.append(f1)\n","    NEN_recalls.append(recall)\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  425 \t NE_sys:  639 \t NE_ref:  4112\n","F1_score:  0.17890970322037467\n","Recall on Nested Entities:  0.19508196721311474\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  998 \t NE_sys:  1597 \t NE_ref:  4112\n","F1_score:  0.34962340164652306\n","Recall on Nested Entities:  0.3704918032786885\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1457 \t NE_sys:  2150 \t NE_ref:  4112\n","F1_score:  0.4653465346534654\n","Recall on Nested Entities:  0.5098360655737705\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1800 \t NE_sys:  2612 \t NE_ref:  4112\n","F1_score:  0.5353955978584176\n","Recall on Nested Entities:  0.5704918032786885\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2077 \t NE_sys:  2915 \t NE_ref:  4112\n","F1_score:  0.5911484274939519\n","Recall on Nested Entities:  0.6245901639344262\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2242 \t NE_sys:  3098 \t NE_ref:  4112\n","F1_score:  0.6219140083217753\n","Recall on Nested Entities:  0.6491803278688525\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2416 \t NE_sys:  3300 \t NE_ref:  4112\n","F1_score:  0.6519158121964382\n","Recall on Nested Entities:  0.6672131147540984\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2547 \t NE_sys:  3443 \t NE_ref:  4112\n","F1_score:  0.6742554599602912\n","Recall on Nested Entities:  0.6934426229508197\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2636 \t NE_sys:  3545 \t NE_ref:  4112\n","F1_score:  0.6885203082147056\n","Recall on Nested Entities:  0.7\n","100\n","200\n","300\n","400\n","500\n","600\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7zZiGdY7cVD","outputId":"d6096f0d-24d7-418c-f0bd-40c8613e5700"},"source":["# Make sure prepare_sequence from earlier in the LSTM section is loaded\n","f1_scores = []\n","NEN_recalls = []\n","for epoch in range(20):\n","    i = 0\n","    for sentence, tags in train_data:\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance         \n","        model.zero_grad()\n","        i+=1\n","        if(i%100) == 0: print(i)\n","        # Step 2. Get our inputs ready for the network, that is,\n","        # turn them into Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence, word_to_ix)\n","        targets = torch.tensor([tag_to_idx[t] for t in tags], dtype=torch.long)\n","\n","        # Step 3. Run our forward pass.\n","        loss = model.neg_log_likelihood(sentence_in, targets)\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        # calling optimizer.step()\n","        loss.backward()\n","        optimizer.step()\n","    preY_val = []\n","\n","    with torch.no_grad():\n","        for sent in X_val:\n","            precheck_sent = prepare_sequence(sent, word_to_ix)\n","            preY_val.append(model(precheck_sent)[1])\n","    y_pred = []\n","    for n_sent in preY_val:\n","        t_sent = []\n","        for nt in n_sent:\n","            t_sent.append(idx_to_tag[nt])\n","        y_pred.append(t_sent)\n","    f1, recall = evaluate(y_pred, Y_val)\n","    f1_scores.append(f1)\n","    NEN_recalls.append(recall)\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  450 \t NE_sys:  697 \t NE_ref:  4112\n","F1_score:  0.1871490954460387\n","Recall on Nested Entities:  0.19672131147540983\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  957 \t NE_sys:  1394 \t NE_ref:  4112\n","F1_score:  0.34762077733381763\n","Recall on Nested Entities:  0.36065573770491804\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1430 \t NE_sys:  2082 \t NE_ref:  4112\n","F1_score:  0.46173716499838546\n","Recall on Nested Entities:  0.4819672131147541\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  1789 \t NE_sys:  2531 \t NE_ref:  4112\n","F1_score:  0.5386120728586482\n","Recall on Nested Entities:  0.5459016393442623\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2048 \t NE_sys:  2858 \t NE_ref:  4112\n","F1_score:  0.587661406025825\n","Recall on Nested Entities:  0.5967213114754099\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2217 \t NE_sys:  3053 \t NE_ref:  4112\n","F1_score:  0.6188415910676901\n","Recall on Nested Entities:  0.6295081967213115\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2399 \t NE_sys:  3239 \t NE_ref:  4112\n","F1_score:  0.652700312882601\n","Recall on Nested Entities:  0.6491803278688525\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2489 \t NE_sys:  3335 \t NE_ref:  4112\n","F1_score:  0.6684570968175104\n","Recall on Nested Entities:  0.6524590163934426\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2586 \t NE_sys:  3467 \t NE_ref:  4112\n","F1_score:  0.6824119276949465\n","Recall on Nested Entities:  0.6688524590163935\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2675 \t NE_sys:  3547 \t NE_ref:  4112\n","F1_score:  0.6985246115680899\n","Recall on Nested Entities:  0.6967213114754098\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2762 \t NE_sys:  3637 \t NE_ref:  4112\n","F1_score:  0.7128661762808104\n","Recall on Nested Entities:  0.7229508196721312\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","7000\n","7100\n","7200\n","7300\n","7400\n","7500\n","7600\n","7700\n","7800\n","7900\n","8000\n","8100\n","8200\n","8300\n","8400\n","8500\n","8600\n","8700\n","8800\n","8900\n","9000\n","9100\n","9200\n","9300\n","9400\n","9500\n","9600\n","9700\n","9800\n","9900\n","10000\n","10100\n","10200\n","10300\n","10400\n","10500\n","10600\n","10700\n","10800\n","10900\n","11000\n","11100\n","11200\n","NE_true:  2808 \t NE_sys:  3669 \t NE_ref:  4112\n","F1_score:  0.7217581287752216\n","Recall on Nested Entities:  0.7311475409836066\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ek6eaFuf7EUM"},"source":[""],"execution_count":null,"outputs":[]}]}